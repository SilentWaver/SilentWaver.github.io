---
title: 爬虫学习
categories:
  - 爬虫
date: 2020-1-1
---


本文主要参考了https://cuijiahua.com/内的爬虫教程

<!--more-->

#### 发起请求：requests，urllib.request库

requests库安装



在cmd中，使用如下指令

```python
pip install requests
```

或

```python
easy——install requests
```

如果遇到请求超时的情况（Read timed out）可使用如下代码

```python
pip --default-timeout=100 install -U xxx
```

xxx为所要安装的第三方库

或者，多试几次XD



#####  解析数据： BeautifulSoup



 Beautiful Soup 是 Python 的一个第三方库，主要用于解析网页数据。 

```
pip install beautifulsoup4
# 或者
easy_install beautifulsoup4
```

之后还需要安装 lxml，这是解析 HTML 需要用到的依赖： 

```
pip install lxml
```



当然如果请求超时也可以用上面那个代码



#### 反爬虫

页面**不能右键**！

这就是**最最最最低级**的[反爬虫](https://cuijiahua.com/blog/tag/反爬虫/)手段，这个时候我们可以通过键盘的**F12**调出审查元素窗口。

有的网站甚至把**F12**都禁掉，这种也是很低级的[反爬虫](https://cuijiahua.com/blog/tag/反爬虫/)手段，骗骗刚入门的手段而已。

面对这种禁止看页面源码的初级手段，一个**优雅的通用解决办法**是，在连接前加个`view-source:`。

<b>referer 反爬虫</b>   

Referer可以理解为来路，先打开章节URL链接，再打开图片链接。打开图片的时候，Referer的信息里保存的是章节URL。

动漫之家网站的做法就是，站内的用户访问这个图片，我就给他看，从其它地方过来的用户，我就不给他看。

是不是站内用户，就是根据Referer进行简单的判断。





#### 动态加载







 



### 问题记录



1.正则表达式

参照了菜鸟教程内的正则表达式教程。

https://www.runoob.com/regexp/regexp-example.html



这是在学习中遇到的一个正则表达式

```python
pics = re.findall('\d{13,14}', str(script_info))
chapterpic_hou = re.findall('\|(\d{5})\|', str(script_info))[0]
chapterpic_qian = re.findall('\|(\d{4})\|', str(script_info))[0]
```



\ d {13,14}  表示匹配一个长度为13~14位数字的号码

\ |  (\d{5}) \ |,可拆为两部分， 首先为\ | ,表示匹配 |，然后为（\d{5}）,表示为匹配一个长度为5位数字的号码，合起来就表示匹配 |xxxxx|，x代表数字。

\|(\d{4})\|，同上。



2.一个小问题

![4](E:\cetools\Hexo\blog\source\4.png)

在上述段落中，有两个长度为5的数字字符串 |14237|与|41917|

但是在教程的输出结果里，却只匹配到了|14237|

```python
chapterpic_hou = re.findall('\|(\d{5})\|', str(script_info))[0]
```

愿因原来很简单，是我自己人傻了TAT 

因为他在最后面加了个[0],限定只要第一个结果，即|14237|

<b>思考：</b> 如果不确定想要的结果具体在第几位，通过一遍搜索找出对应项？





